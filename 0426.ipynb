{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialization\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"marvel\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "## import library\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml.feature import RFormula\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.awsAccessKeyId\", \"AKIAQYYJWECSO4ERCXUU\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.awsSecretAccessKey\", \"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\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3.awsAccessKeyId\", \"AKIAQYYJWECSO4ERCXUU\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3.awsSecretAccessKey\", \"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\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsAccessKeyId\", \"AKIAQYYJWECSO4ERCXUU\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsSecretAccessKey\", \"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.read.json(\"s3n://mv559/reddit/sample-data/1m-line-sample.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupBy(\"subreddit_type\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test.groupBy('no_follow').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=data['no_follow'],y = data['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = test.select(\"c\").toPandas()\n",
    "sns.kdeplot(score1.score,shade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupBy(\"stickied\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = test.withColumn(\"no_follow\",test['no_follow'].cast(\"int\"))\n",
    "new_data = new_data.withColumn(\"collapsed\",test['collapsed'].cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contro = test.select(\"controversiality\").toPandas()\n",
    "sns.kdeplot(contro.controversiality,shade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.createOrReplaceTempView(\"new_converted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.sql(\"\"\"SELECT *,\n",
    "CASE WHEN score <= 5 AND score > 0 THEN 'little like'\n",
    "     WHEN score <= 0 THEN 'unlike'\n",
    "     WHEN score >= 20000 THEN 'strongly like'\n",
    "     ELSE 'like' END AS score_bin\n",
    "FROM new_converted\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- archived: boolean (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- author_cakeday: boolean (nullable = true)\n",
      " |-- author_created_utc: long (nullable = true)\n",
      " |-- author_flair_background_color: string (nullable = true)\n",
      " |-- author_flair_css_class: string (nullable = true)\n",
      " |-- author_flair_richtext: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- a: string (nullable = true)\n",
      " |    |    |-- e: string (nullable = true)\n",
      " |    |    |-- t: string (nullable = true)\n",
      " |    |    |-- u: string (nullable = true)\n",
      " |-- author_flair_template_id: string (nullable = true)\n",
      " |-- author_flair_text: string (nullable = true)\n",
      " |-- author_flair_text_color: string (nullable = true)\n",
      " |-- author_flair_type: string (nullable = true)\n",
      " |-- author_fullname: string (nullable = true)\n",
      " |-- author_patreon_flair: boolean (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- can_gild: boolean (nullable = true)\n",
      " |-- can_mod_post: boolean (nullable = true)\n",
      " |-- collapsed: integer (nullable = true)\n",
      " |-- collapsed_reason: string (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- created_utc: long (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      " |-- edited: string (nullable = true)\n",
      " |-- gilded: long (nullable = true)\n",
      " |-- gildings: struct (nullable = true)\n",
      " |    |-- gid_1: long (nullable = true)\n",
      " |    |-- gid_2: long (nullable = true)\n",
      " |    |-- gid_3: long (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- is_submitter: boolean (nullable = true)\n",
      " |-- link_id: string (nullable = true)\n",
      " |-- no_follow: integer (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      " |-- permalink: string (nullable = true)\n",
      " |-- removal_reason: string (nullable = true)\n",
      " |-- retrieved_on: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- send_replies: boolean (nullable = true)\n",
      " |-- stickied: boolean (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- subreddit_id: string (nullable = true)\n",
      " |-- subreddit_name_prefixed: string (nullable = true)\n",
      " |-- subreddit_type: string (nullable = true)\n",
      " |-- score_bin: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = StringIndexer(inputCol=\"subreddit_type\", outputCol=\"subreddit_si\")\n",
    "s2 = StringIndexer(inputCol=\"score_bin\", outputCol=\"score_bin_si\")\n",
    "e1 = OneHotEncoder(inputCol=\"subreddit_si\", outputCol=\"subreddit_vec\", dropLast=False)\n",
    "e2 = OneHotEncoder(inputCol=\"score_bin_si\", outputCol=\"score_bin_vec\", dropLast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tran = Pipeline(stages=[s1, e1,s2, e2]).fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### put the data into 90% training and 10% test data\n",
    "sample1 = df_tran.sample(0.1,seed = 0)\n",
    "splitted = sample1.randomSplit([0.9,0.1],1234)\n",
    "train = splitted[0]\n",
    "test = splitted[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build LogisticRegression model and train them using pipeline\n",
    "fit_log_1 = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create LogisticRegression predictors\n",
    "class1 = RFormula(formula=\"no_follow ~ subreddit_si +  score_bin_si + collapsed + controversiality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train the data\n",
    "model = Pipeline(stages = [class1,fit_log_1]).fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### predict for test data\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make a rdd for predictions and true value\n",
    "pred = predictions['label', 'prediction'].rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### confusion matrix\n",
    "con_metrics = BinaryClassificationMetrics(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=0.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=0.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=0.0, prediction=1.0),\n",
       " Row(label=0.0, prediction=1.0),\n",
       " Row(label=0.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=0.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=0.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=0.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=0.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=0.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=0.0, prediction=1.0),\n",
       " Row(label=0.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=0.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=0.0, prediction=1.0),\n",
       " Row(label=0.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0),\n",
       " Row(label=1.0, prediction=1.0)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print first ten results\n",
    "pred.take(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Area under ROC = %s\" % con_metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
